{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"19H4fgYJtMxaIm0WNoVqibF_R-BxHZ-ZV","timestamp":1700026697249},{"file_id":"1GXJl74bt4tlP8PawjEYTBzpPj2pERXV1","timestamp":1699851787882}],"mount_file_id":"1GXJl74bt4tlP8PawjEYTBzpPj2pERXV1","authorship_tag":"ABX9TyMwjQWz9S0Scah03wMA3fID"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**1. Mounting Google Drive**"],"metadata":{"id":"zYPMm-Z-fUe9"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":291},"id":"336e7oLq9UxT","executionInfo":{"status":"error","timestamp":1711687099484,"user_tz":-660,"elapsed":4370,"user":{"displayName":"Archit Aggarwal","userId":"13213088458031787112"}},"outputId":"dac94392-12af-47ba-b017-67b6a533dd9a"},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a145c0899d7d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","source":["**2. Install necesarry libraries**"],"metadata":{"id":"gF8JSdqafeha"}},{"cell_type":"code","source":["pip install laserembeddings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tinSzaefNgbl","executionInfo":{"status":"ok","timestamp":1701322082967,"user_tz":-660,"elapsed":142240,"user":{"displayName":"Archit Aggarwal","userId":"13213088458031787112"}},"outputId":"3a099b47-80d9-4c7b-bb8e-af47c8870b24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting laserembeddings\n","  Downloading laserembeddings-1.1.2-py3-none-any.whl (13 kB)\n","Requirement already satisfied: numpy<2.0.0,>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from laserembeddings) (1.23.5)\n","Collecting sacremoses==0.0.35 (from laserembeddings)\n","  Downloading sacremoses-0.0.35.tar.gz (859 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.8/859.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting subword-nmt<0.4.0,>=0.3.6 (from laserembeddings)\n","  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n","Collecting torch<2.0.0,>=1.0.1.post2 (from laserembeddings)\n","  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transliterate==1.10.2 (from laserembeddings)\n","  Downloading transliterate-1.10.2-py2.py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.35->laserembeddings) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.35->laserembeddings) (1.3.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.35->laserembeddings) (4.66.1)\n","Collecting mock (from subword-nmt<0.4.0,>=0.3.6->laserembeddings)\n","  Downloading mock-5.1.0-py3-none-any.whl (30 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.0.0,>=1.0.1.post2->laserembeddings) (4.5.0)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<2.0.0,>=1.0.1.post2->laserembeddings)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<2.0.0,>=1.0.1.post2->laserembeddings)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<2.0.0,>=1.0.1.post2->laserembeddings)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<2.0.0,>=1.0.1.post2->laserembeddings)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0.0,>=1.0.1.post2->laserembeddings) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0.0,>=1.0.1.post2->laserembeddings) (0.41.3)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883963 sha256=984b2d7fc520b4ffdeb3ba6e7c169cfa14dfa6213f73951d9672cc03a54607cf\n","  Stored in directory: /root/.cache/pip/wheels/8e/12/4b/5c9eeed3636a4041c004e859e03429a49105672c7fb09ba6d9\n","Successfully built sacremoses\n","Installing collected packages: transliterate, sacremoses, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, mock, subword-nmt, nvidia-cudnn-cu11, torch, laserembeddings\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.0+cu118\n","    Uninstalling torch-2.1.0+cu118:\n","      Successfully uninstalled torch-2.1.0+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\n","torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\n","torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\n","torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed laserembeddings-1.1.2 mock-5.1.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 sacremoses-0.0.35 subword-nmt-0.3.8 torch-1.13.1 transliterate-1.10.2\n"]}]},{"cell_type":"code","source":["!pip install indic-nlp-library"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oxbVC4v2RNXK","executionInfo":{"status":"ok","timestamp":1700893801302,"user_tz":-660,"elapsed":13572,"user":{"displayName":"Archit Aggarwal","userId":"13213088458031787112"}},"outputId":"e1d44d1b-4cd1-4e53-9f07-8f0652a1bfb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting indic-nlp-library\n","  Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sphinx-argparse (from indic-nlp-library)\n","  Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n","Collecting sphinx-rtd-theme (from indic-nlp-library)\n","  Downloading sphinx_rtd_theme-1.3.0-py2.py3-none-any.whl (2.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting morfessor (from indic-nlp-library)\n","  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (1.5.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (1.23.5)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2023.3.post1)\n","Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library) (5.0.2)\n","Requirement already satisfied: docutils<0.19 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (0.18.1)\n","Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n","  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->indic-nlp-library) (1.16.0)\n","Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.7)\n","Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.5)\n","Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n","Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.4)\n","Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.9)\n","Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.6)\n","Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.2)\n","Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.16.1)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n","Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.13.1)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.13)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n","Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.31.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (23.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2023.7.22)\n","Installing collected packages: morfessor, sphinxcontrib-jquery, sphinx-rtd-theme, sphinx-argparse, indic-nlp-library\n","Successfully installed indic-nlp-library-0.92 morfessor-2.0.6 sphinx-argparse-0.4.0 sphinx-rtd-theme-1.3.0 sphinxcontrib-jquery-4.1\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lqQ2Z1JkRb2R","executionInfo":{"status":"ok","timestamp":1700893803986,"user_tz":-660,"elapsed":2704,"user":{"displayName":"Archit Aggarwal","userId":"13213088458031787112"}},"outputId":"8e1db2d1-0f46-4f25-ace6-1da61a4a102c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["!python -m laserembeddings download-models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mvr0XUlMW4G_","executionInfo":{"status":"ok","timestamp":1700893813314,"user_tz":-660,"elapsed":9335,"user":{"displayName":"Archit Aggarwal","userId":"13213088458031787112"}},"outputId":"0c66ebdb-365f-49d4-a4f3-5b6704d5184f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading models into /usr/local/lib/python3.10/dist-packages/laserembeddings/data\n","\n","✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fcodes    \n","✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/93langs.fvocab    \n","✅   Downloaded https://dl.fbaipublicfiles.com/laser/models/bilstm.93langs.2018-12-26.pt    \n","\n","✨ You're all set!\n"]}]},{"cell_type":"code","source":["from laserembeddings import Laser\n","import numpy as np\n","from indicnlp.tokenize import sentence_tokenize\n","import jieba\n","import os\n","import re"],"metadata":{"id":"RLj9oT2d9ZRR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"],"metadata":{"id":"Lx3zo0T8NEJV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["laser = Laser()"],"metadata":{"id":"JZyVvytK9jQF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_path = \"/content/drive/MyDrive/thesis-data\"\n","english_folder = os.path.join(base_path, \"Articles/English_Articles\")\n","hindi_folder = os.path.join(base_path, \"Articles/Hindi_Articles\")\n","afrikaans_folder = os.path.join(base_path, \"Articles/Afrikaans_Articles\")  # Add Afrikaans folder\n","chinese_folder = os.path.join(base_path, \"Articles/Chinese_Articles\")      # Add Chinese folder\n","aligned_folder_en_hi = os.path.join(base_path, \"Aligned_Articles-LASER/Aligned_Articles_En_Hi\")\n","aligned_folder_en_af = os.path.join(base_path, \"Aligned_Articles-LASER/Aligned_Articles_En_Af\")\n","aligned_folder_en_zh = os.path.join(base_path, \"Aligned_Articles-LASER/Aligned_Articles_En_Zh\")"],"metadata":{"id":"sO5x7KXtlVAF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def write_aligned_pairs(aligned_folder, file_identifier, aligned_pairs):\n","    os.makedirs(aligned_folder, exist_ok=True)\n","    aligned_file_path = os.path.join(aligned_folder, f\"{file_identifier}_aligned.txt\")\n","    with open(aligned_file_path, 'w', encoding='utf-8') as file:\n","        for eng, hin in aligned_pairs:\n","            file.write(f\"{eng} ----> {hin}\\n\")"],"metadata":{"id":"1bSOWNT8UqmN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def read_text_file(folder, file_name):\n","    with open(os.path.join(folder, file_name), 'r', encoding='utf-8') as f:\n","        return f.read()\n","\n","def write_aligned_to_file(folder, wikidata_id, aligned_pairs):\n","    os.makedirs(folder, exist_ok=True)  # This should create the folder if it doesn't exist\n","\n","    if not os.path.exists(folder):  # Check if the directory was indeed created\n","        print(f\"Failed to create directory: {folder}\")\n","        return\n","    file_path = os.path.join(folder, f\"{wikidata_id}_aligned.txt\")\n","    with open(file_path, 'w', encoding='utf-8') as f:\n","        for pair in aligned_pairs:\n","            if len(pair) == 2 and all(pair):\n","                eng, hin = pair\n","                f.write(f\"{eng} ----> {hin} \\n\")"],"metadata":{"id":"XHIiaqh6CkI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_sentences(file_path, language_code):\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        text = file.read()\n","\n","    if language_code in ['en', 'af']:  # English or Afrikaans\n","        sentences = nltk.sent_tokenize(text, language='english')\n","    elif language_code == 'hi':\n","        sentences = sentence_tokenize.sentence_split(text, lang='hi')\n","    elif language_code == 'zh':  # Chinese\n","        sentences = re.split(r\"(。|！|？|；)\", text)\n","    # Join the Chinese full stops back to the sentences (which are at every odd index)\n","        sentences = [sentences[i] + (sentences[i + 1] if i + 1 < len(sentences) else '')\n","                 for i in range(0, len(sentences), 2)]\n","    else:\n","        raise ValueError(f\"Unsupported language_code: {language_code}\")\n","\n","    return sentences"],"metadata":{"id":"mJZK4MMxUKiD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["***USING COSINE SIMILARITY HERE***"],"metadata":{"id":"Wy5mlaFnZ0b2"}},{"cell_type":"code","source":["from sklearn.metrics.pairwise import cosine_similarity"],"metadata":{"id":"oMKe6G-vaAq5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def align_and_store_articles(source_folder, target_folder, aligned_folder, source_language, target_language,min_similarity):\n","\n","    source_files = sorted([f for f in os.listdir(source_folder) if f.endswith('.txt')])\n","    target_files = sorted([f for f in os.listdir(target_folder) if f.endswith('.txt')])\n","    logging.info(f\"Processing articles for {source_language}-{target_language} alignment\")\n","\n","    for i in range(0, len(source_files), 10):\n","        source_chunk = source_files[i:i+10]\n","        target_chunk = target_files[i:i+10]\n","        for source_file, target_file in zip(source_files, target_files):\n","          source_sentences = get_sentences(os.path.join(source_folder, source_file), source_language)\n","          target_sentences = get_sentences(os.path.join(target_folder, target_file), target_language)\n","\n","          source_embeddings = laser.embed_sentences(source_sentences, lang=source_language)\n","          target_embeddings = laser.embed_sentences(target_sentences, lang=target_language)\n","\n","          similarity_matrix = cosine_similarity(source_embeddings, target_embeddings)\n","\n","          source_matched, target_matched = set(), set()\n","          aligned_pairs = []\n","\n","          for src_index, tgt_index in zip(*np.unravel_index(np.argsort(-similarity_matrix, axis=None), similarity_matrix.shape)):\n","              if similarity_matrix[src_index, tgt_index] >= min_similarity:\n","                  if src_index not in source_matched and tgt_index not in target_matched:\n","                      aligned_pairs.append((source_sentences[src_index], target_sentences[tgt_index]))\n","                      source_matched.add(src_index)\n","                      target_matched.add(tgt_index)\n","\n","          if len(aligned_pairs) > 0:\n","              write_aligned_pairs(aligned_folder, source_file.replace('.txt', ''), aligned_pairs)\n","              logging.info(f\"Created aligned file for {source_file}\")\n","          else:\n","              logging.warning(f\"No alignment created for {source_file} due to insufficient similarity or sentence pairs\")\n"],"metadata":{"id":"kdGH8ttQZ7ql"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def align_and_store_articles(source_folder, target_folder, output_folder, source_language, target_language, min_similarity):\n","    source_files = sorted([f for f in os.listdir(source_folder) if f.endswith('.txt')])\n","    target_files = sorted([f for f in os.listdir(target_folder) if f.endswith('.txt')])\n","\n","    for i in range(0, len(source_files), 10):\n","        source_chunk = source_files[i:i+10]\n","        target_chunk = target_files[i:i+10]\n","\n","        for source_file, target_file in zip(source_chunk, target_chunk):\n","            try:\n","                source_sentences = get_sentences(os.path.join(source_folder, source_file), source_language)\n","                target_sentences = get_sentences(os.path.join(target_folder, target_file), target_language)\n","\n","                source_embeddings = laser.embed_sentences(source_sentences, lang=source_language)\n","                target_embeddings = laser.embed_sentences(target_sentences, lang=target_language)\n","\n","                similarity_matrix = cosine_similarity(source_embeddings, target_embeddings)\n","\n","                source_matched, target_matched = set(), set()\n","                aligned_pairs = []\n","\n","                for src_index, tgt_index in zip(*np.unravel_index(np.argsort(-similarity_matrix, axis=None), similarity_matrix.shape)):\n","                    if similarity_matrix[src_index, tgt_index] >= min_similarity:\n","                        if src_index not in source_matched and tgt_index not in target_matched:\n","                            aligned_pairs.append((source_sentences[src_index], target_sentences[tgt_index]))\n","                            source_matched.add(src_index)\n","                            target_matched.add(tgt_index)\n","\n","                if len(aligned_pairs) > 0:\n","                    write_aligned_pairs(output_folder, source_file.replace('.txt', ''), aligned_pairs)\n","                    logging.info(f\"Created aligned file for {source_file}\")\n","                else:\n","                    logging.warning(f\"No alignment created for {source_file} due to insufficient similarity or sentence pairs\")\n","\n","            except Exception as e:\n","                logging.error(f\"Error processing {source_file}: {e}\")\n"],"metadata":{"id":"emYoqWorVwub"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","def count_files_in_folder(directory):\n","    return len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n","\n","# Example usage\n","folder_path = '/content/drive/MyDrive/thesis-data/Aligned_Articles-LASER/Aligned_Articles_En_Zh'\n","file_count = count_files_in_folder(folder_path)\n","print(f\"There are {file_count} files in the folder.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5KYT2v6PKPNy","executionInfo":{"status":"ok","timestamp":1700896031700,"user_tz":-660,"elapsed":10,"user":{"displayName":"Archit Aggarwal","userId":"13213088458031787112"}},"outputId":"0105be21-e5e2-46cf-9495-c89cc59730e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 162 files in the folder.\n"]}]},{"cell_type":"code","source":["align_and_store_articles(english_folder, hindi_folder, aligned_folder_en_hi, 'en', 'hi',0.7)"],"metadata":{"id":"2iXD9HXxD1hj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["align_and_store_articles(english_folder, afrikaans_folder, aligned_folder_en_af, 'en', 'af',0.76)"],"metadata":{"id":"YtzIfLCGjzqn","executionInfo":{"status":"error","timestamp":1700896917770,"user_tz":-660,"elapsed":42440,"user":{"displayName":"Archit Aggarwal","userId":"13213088458031787112"}},"colab":{"base_uri":"https://localhost:8080/","height":375},"outputId":"599f537e-f41c-459f-ec5c-acb05c1f17db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:No alignment created for Q10294.txt due to insufficient similarity or sentence pairs\n","WARNING:root:No alignment created for Q105196.txt due to insufficient similarity or sentence pairs\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-8c27fb2b7e6d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malign_and_store_articles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menglish_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafrikaans_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maligned_folder_en_af\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'af'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.76\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-48-39c8c4dfdde0>\u001b[0m in \u001b[0;36malign_and_store_articles\u001b[0;34m(source_folder, target_folder, output_folder, source_language, target_language, min_similarity)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0msource_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlaser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mtarget_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlaser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0msimilarity_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/laserembeddings/laser.py\u001b[0m in \u001b[0;36membed_sentences\u001b[0;34m(self, sentences, lang)\u001b[0m\n\u001b[1;32m    120\u001b[0m             ]\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbpeSentenceEmbedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_bpe_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbpe_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/laserembeddings/embedding.py\u001b[0m in \u001b[0;36membed_bpe_sentences\u001b[0;34m(self, bpe_sentences)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0mNumPy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0msentences\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \"\"\"\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbpe_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/laserembeddings/encoder.py\u001b[0m in \u001b[0;36mencode_sentences\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_indices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_kind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/laserembeddings/encoder.py\u001b[0m in \u001b[0;36m_process_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentemb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/laserembeddings/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_tokens, src_lengths)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         packed_outs, (final_hiddens,\n\u001b[0;32m--> 205\u001b[0;31m                       final_cells) = self.lstm(packed_x, (h0, c0))\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# unpack outputs and apply dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    775\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0m\u001b[1;32m    778\u001b[0m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[1;32m    779\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["align_and_store_articles(english_folder, chinese_folder, aligned_folder_en_zh, 'en', 'zh',0.75)"],"metadata":{"id":"uyHW7PsFwBNZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qK754ZtrQjeq"},"execution_count":null,"outputs":[]}]}